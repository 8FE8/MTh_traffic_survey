{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBG7ZQ_pcEah"
   },
   "source": [
    "# Object Detection with Faster R-CNN Transfer Learning\n",
    "## Initial document from Adrian Meyer and further processing by Elia Ferrari and Marius HÃ¼rzeler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWJHCmFs_Vg6"
   },
   "source": [
    "# Download Tensorflow Repo and Python Modules\n",
    "By executing the first code snippet you initialize your virtual linux-style machine. Use The little arrow \">\" in the top left corner to view the file system of your hosted system.\n",
    "You can use UNIX-style terminal commands by using the prefix % and elevated priviledge commands for installations with the prefix !."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OpYysyTXxEC"
   },
   "outputs": [],
   "source": [
    "#make sure numpy is downgraded for compatibility reasons.\n",
    "!pip install numpy==1.17.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yTOMQYb9SN7"
   },
   "outputs": [],
   "source": [
    "%cd\n",
    "%tensorflow_version 1.x\n",
    "\n",
    "#make sure to be in /root and that tensorflow is running in version 1.15.2\n",
    "#%load_ext tensorboard# Load the TensorBoard notebook extension \n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#!rm -rf ./logs/#remove logs from previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-ZCWNSXW1mI"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This allows you to check which GPU you have been allocated. Google offers free\n",
    "Tesla T4, Tesla K80, Tesla P100 (the P100 hax 1.6x more GFLOPs and 3x the memory bandwith than K80, the T4 is fairly slow).\n",
    "In theory you can restart the environment until you have the fast one. \n",
    "For testing and learning it doesn't really matter.\n",
    "\"\"\"\n",
    "  \n",
    "#We have to work with Tensorflow 1.15.2 for code compatibility reasons; by now TF v2 is available.\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dyvc3xTxsy0"
   },
   "outputs": [],
   "source": [
    "%cd\n",
    "%tensorflow_version 1.x\n",
    "\n",
    "#make sure to be in /root and that tensorflow is running in version 1.15.2\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\"\"\"\n",
    "This repository contains a number of different models implemented in TensorFlow: The official models are a collection of example models that use TensorFlows high-level APIs. They are intended to be well-maintained, tested, and kept up to date with the latest stable TensorFlow API. They should also be reasonably optimized for fast performance while still being easy to read. We especially recommend newer TensorFlow users to start here.\n",
    "The research models are a large collection of models implemented in TensorFlow by researchers. They are not officially supported or available in release branches; it is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.\n",
    "The samples folder contains code snippets and smaller models that demonstrate features of TensorFlow, including code presented in various blog posts.\n",
    "\"\"\"\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "\n",
    "!apt-get install protobuf-compiler python-tk\n",
    "\n",
    "\"\"\"\n",
    "Protocol buffers are Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data; similar to JSON or XML.\n",
    "\"\"\"\n",
    "!pip install Cython contextlib2 pillow lxml matplotlib PyDrive\n",
    "\"\"\"\n",
    "These context modules are necessary python pachages. Especially Cython is important: It allows to call native C or C++ bindings from within python.\n",
    "\"\"\"\n",
    "\n",
    "!pip install pycocotools\n",
    "\"\"\"\n",
    "COCO is a large image dataset designed for object detection, segmentation, person keypoints detection, stuff segmentation, and caption generation. \n",
    "\"\"\"\n",
    "\n",
    "%cd ~/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=. \n",
    "#This initializes/compiles the Tensorflow Protobuf evnironment.\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += ':/models/research/:/models/research/slim/'\n",
    "#This sets the file system path for the python interpreter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVXThN8P_itE"
   },
   "source": [
    "# Install Tensorflow on Virtual Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Alxt_PF4yBae"
   },
   "outputs": [],
   "source": [
    "!python setup.py build\n",
    "!python setup.py install > /dev/null\n",
    "\"\"\"\n",
    "This snippet builds and installs the Tensorflow API from the cloned git source.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THX1UucO0L5X"
   },
   "outputs": [],
   "source": [
    "%cd slim\n",
    "!pip install -e .\n",
    "\n",
    "%cd ..\n",
    "!python object_detection/builders/model_builder_test.py\n",
    "\"\"\"\n",
    "This tests if the installation was successful. The Tests should yield the output [ RUN  OK ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceHKJMfzHdg9"
   },
   "source": [
    "#Upload and Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CI9EJ13NBLVd"
   },
   "outputs": [],
   "source": [
    "#Here you can your dataset dowload\n",
    "%cd /datalab\n",
    "!wget https://drive.switch.ch/index.php/s/tqRSOcRs0FxUzvF/download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaaI150MDVLq"
   },
   "outputs": [],
   "source": [
    "%cd /datalab\n",
    "!mv download datensatz.zip\n",
    "#In case you have unwanted folders remaining in your file system use this command: !rm -r FOLDERNAME\n",
    "!unzip datensatz.zip #Scroll through the unzip output to get an idea of the datalab folder content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPuTXqAuVr-6"
   },
   "source": [
    "#Data and Model Preparation\n",
    "The dataset has to be transformed in a readable and trainable format. This step includes reading the XML information, generating bounding boxes and producing mathematical tensors as input for the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6f41p5Nb1Uhl"
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%cd /datalab\n",
    "\n",
    "!echo \"item { id: 1 name: 'car'}\" > label_map.pbtxt\n",
    "!echo \"item { id: 2 name: 'bike'}\" >> label_map.pbtxt\n",
    "!echo \"item { id: 3 name: 'person'}\" >> label_map.pbtxt\n",
    "!echo \"item { id: 4 name: 'tram'}\" >> label_map.pbtxt\n",
    "!echo \"item { id: 5 name: 'motorbike'}\" >> label_map.pbtxt\n",
    "\n",
    "image_files=os.listdir('images')\n",
    "im_files=[x.split('.')[0] for x in image_files]\n",
    "with open('annotations/trainval.txt', 'w') as text_file:\n",
    "  for row in im_files:\n",
    "    text_file.write(row + '\\n')\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "osh2Ty-vTejr"
   },
   "source": [
    "We need to write our label name (in this case for example \"car\") into a config file defining all detectable classes.\n",
    "It can be one or multiple classes. If you want to start a new file use the \">\" pipe command. If you want to append a line use the \">>\" pipe command.\n",
    "\n",
    "Then we iterate through all image files to extract the file names (paths are not relevant) which we want to use for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z585EAj7ZY8W"
   },
   "outputs": [],
   "source": [
    "%cd /datalab\n",
    "!python xml_to_csv.py\n",
    "#This script takes the XML annotations from the 'train' and 'test' folders and writes them as a list into \n",
    "#two CSV table files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jiE8dMrBMGTG"
   },
   "source": [
    "## Generate Bounding Boxes on Images for RPN Network Training\n",
    "The same process need to be performed with the XML Annotation files.\n",
    "Additionally, we write PNG files containing the masks of our labelled areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r38LiZJ11nJ2"
   },
   "outputs": [],
   "source": [
    "%cd /datalab/annotations\n",
    "!rm -r trimaps\n",
    "!mkdir trimaps\n",
    "\n",
    "from PIL import Image\n",
    "image = Image.new('RGB', (1000, 800))\n",
    "\n",
    "for filename in os.listdir('xmls'):\n",
    "  filename = os.path.splitext(filename)[0]\n",
    "  image.save('trimaps/' + filename + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSWgp44im5OC"
   },
   "source": [
    "##Generate Labelled Tensor Matrices (tf_records)\n",
    "The Tensorflow Record files contain the actual input data for the Machine Learning process in binary format. An API specific script can do the job for us. We use the famous \"coco model\" in our transfer learning process. The dataset needs to be split at this point into training and validation data. 80% of our data should be used for training, the remaining 20% for validation (testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUwiv8t1M45B"
   },
   "outputs": [],
   "source": [
    "%cd /datalab\n",
    "!python generate_tfrecord.py --csv_input=splitted/train_labels.csv --image_dir=splitted/train --output_path=tf_train.record\n",
    "!python generate_tfrecord.py --csv_input=splitted/test_labels.csv --image_dir=splitted/test --output_path=tf_val.record\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0CoGNKoMiCr"
   },
   "source": [
    "##Download the Model Checkpoint you want to use for Transfer Learning\n",
    "Many different COCO pretrained neural models can be used for bounding box related object detection with Tensorflow.\n",
    "They all have different advantages or disadvantages (e.g. inferencing speed, accuracy, easy to train, etc.).\n",
    "\n",
    "An overview can be found with the [TF Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Sj2b08bHfmZ"
   },
   "outputs": [],
   "source": [
    "%cd /datalab\n",
    "!wget http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
    "  \n",
    "%cd /datalab\n",
    "!tar -xvzf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
    "\n",
    "%cd /datalab\n",
    "!mv faster_rcnn_inception_v2_coco_2018_01_28 pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qyk6YNdBMq8A"
   },
   "source": [
    "##Configure the Paths and Training Parameters\n",
    "This specifies which files and model checkpoints should be used for the trainings process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkNT0AWT6Q9K"
   },
   "outputs": [],
   "source": [
    "%cd /datalab\n",
    "\n",
    "import re\n",
    "\n",
    "#filename = '/datalab/pretrained_model/pipeline.config'\n",
    "filename = '/root/models/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config'\n",
    "with open(filename) as f:\n",
    "  s = f.read()\n",
    "with open(filename, 'w') as f:\n",
    "  s = re.sub('    num_classes: 90', '    num_classes: 3', s)\n",
    "  s = re.sub('PATH_TO_BE_CONFIGURED/model.ckpt', '/datalab/pretrained_model/model.ckpt', s)\n",
    "  s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_train.record-\\?\\?\\?\\?\\?-of-00100', '/datalab/tf_train.record', s)\n",
    "  s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_val.record-\\?\\?\\?\\?\\?-of-00010', '/datalab/tf_val.record', s)\n",
    "  s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt', '/datalab/label_map.pbtxt', s)\n",
    "  f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aiJ6kHszMyeJ"
   },
   "source": [
    "# Training on GPU\n",
    "\n",
    "As a rough estimate, the loss value of Faster RCNN models should fall below 0.05 over a few thousand steps and then the training can be aborted. \n",
    "\n",
    "We configure automatic termination after 3'000 Steps, in productive trainings as much as 100'000-200'000 Steps can be neccesary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsoK-GSleCGj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lgz9ULLtlqEK"
   },
   "outputs": [],
   "source": [
    "# here can you download the last checkpoint\n",
    "%cd /datalab\n",
    "#!wget https://drive.switch.ch/index.php/s/Y7bPYdtf2C8FBYq/download #120000 steps with cars, people, bikes and motorbike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Egv_AIJNkDL8"
   },
   "outputs": [],
   "source": [
    "#unzip the data for the last checkpoint\n",
    "%cd /datalab\n",
    "!mv download chkpt.zip\n",
    "#In case you have unwanted folders remaining in your file system use this command: !rm -r FOLDERNAME\n",
    "!unzip chkpt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jvGQxjNI6QNr"
   },
   "outputs": [],
   "source": [
    "%cd /datalab\n",
    "%cp -R /datalab /content\n",
    "#make a temporary copy of the dataset\n",
    "#training for a higher number of steps increases the later achievable accuracy.\n",
    "\n",
    "!python ~/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path=/root/models/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config \\\n",
    "    --model_dir=/datalab/trained \\\n",
    "    --train_dir=/datalab/trained \\\n",
    "    --logtostderr \\\n",
    "    --logdir=/datalab/trained \\\n",
    "    --num_train_steps=121000 \\\n",
    "    --num_eval_steps=1000 \\\n",
    "    --max_evals=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4eq7nPR8wNh"
   },
   "outputs": [],
   "source": [
    "# zip the last checkpoint\n",
    "%cd /datalab\n",
    "!zip -r /checkpoint.zip trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mylJH1tFQNgj"
   },
   "outputs": [],
   "source": [
    "# download the last checkpoint as *.zip for further use\n",
    "from google.colab import files\n",
    "files.download(\"/checkpoint.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6aIMnXJOm49"
   },
   "source": [
    "# Export Inference Graph\n",
    "Inferencing means to apply the model to images which haven't been used for training.\n",
    "\n",
    "We reserved a few images to check if our model performs correctly.\n",
    "\n",
    "The frozen Inference Graph gets generated from the last model checkpoint and contains all elements of the model neccesary to perform inference (also on weaker hardware), but it cannot be used to continue training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsjkGdgTDmbh"
   },
   "outputs": [],
   "source": [
    "%cd /datalab\n",
    "\n",
    "lst = os.listdir('trained')\n",
    "lf = filter(lambda k: 'model.ckpt-' in k, lst)\n",
    "last_model = sorted(lf)[-1].replace('.meta', '')\n",
    "\n",
    "!python ~/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path=/root/models/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config \\\n",
    "    --output_directory=fine_tuned_model \\\n",
    "    --trained_checkpoint_prefix=trained/$last_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqAjy3fpOzlZ"
   },
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4tO_OCUXEvjr"
   },
   "outputs": [],
   "source": [
    "%cd /root/models/research/object_detection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "#if tf.__version__ < '1.4.0':\n",
    "#  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# What model to download.\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = '/datalab/fine_tuned_model' + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('/content/datalab', 'label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Path to images to get classiefied\n",
    "path_to_images = '/datalab/images/'\n",
    "images = os.listdir(path_to_images)\n",
    "images_path = [os.path.join(path_to_images,i ) for i in images]\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (18, 12)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict\n",
    "\n",
    "try:\n",
    "  os.mkdir(\"/datalab/results\")\n",
    "  os.mkdir(\"/datalab/label\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "counter = 0\n",
    "for image_path in images_path:\n",
    "  filename = image_path.split(\"/\")[-1]\n",
    "  image = Image.open(image_path)\n",
    "  imname = os.path.basename(image_path).split('.')[0]\n",
    "  # the array based representation of the image will be used later in order to prepare the\n",
    "  # result image with boxes and labels on it.\n",
    "  image_np = load_image_into_numpy_array(image)\n",
    "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "  # Actual detection.\n",
    "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "  # Visualization of the results of a detection.\n",
    "  '''vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks'),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=4)\n",
    "  plt.imsave( \"/datalab/results/{}\".format(filename),image_np)'''\n",
    "  # Save the boundingboxes\n",
    "  list0=[]\n",
    "  list2=[]\n",
    "  list1=[]\n",
    "  for elem in output_dict['detection_scores']:\n",
    "    list0 += [elem]\n",
    "  for elem1 in output_dict['detection_classes']:\n",
    "    list1 += [elem1]\n",
    "  for elem2 in output_dict['detection_boxes']:\n",
    "    centroidx = (elem2[0]+elem2[2])/2\n",
    "    centroidy = (elem2[1]+elem2[3])/2\n",
    "    list2 += [(centroidx,centroidy)]\n",
    "  import csv\n",
    "  csv_columns =  ['detection_scores','detection_classes','detection_boxes']\n",
    "\n",
    "  with open('/datalab/label/'+imname+'.csv','w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "    csvspam = csv.writer(csvfile, delimiter=',')\n",
    "    for i in range(output_dict['num_detections']):\n",
    "      if lista[i] > 0.70:\n",
    "        csvspam.writerow([list0[i],list1[i],list2[i]])\n",
    "  if counter%10==0:\n",
    "    print(counter)\n",
    "  counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlvunlDAMsK1"
   },
   "outputs": [],
   "source": [
    "# play sound when finished\n",
    "from google.colab import output\n",
    "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8yoooyS8eCk6"
   },
   "outputs": [],
   "source": [
    "# zip the classified images and the centroids data\n",
    "!zip -r /datalab/label.zip /datalab/label/\n",
    "!zip -r /datalab/results.zip /datalab/results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZVWrSc47i4m4"
   },
   "outputs": [],
   "source": [
    "# dowload the results\n",
    "from google.colab import files\n",
    "files.download(\"datalab/label.zip\")\n",
    "files.download(\"datalab/results.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_Verkehrsverhalten_Elia.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
