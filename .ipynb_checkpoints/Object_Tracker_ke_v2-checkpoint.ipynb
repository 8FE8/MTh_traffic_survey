{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vertiefungsprojekt 1\n",
    "<h1>Master of Science in Engineering, Profile Geomatics\n",
    "<h1>Patrick Keusch\n",
    "\n",
    "<h3>Source code partially from AIGuy, adaptions by Patrick Keusch\n",
    "https://github.com/theAIGuysCode/yolov4-custom-functions\n",
    "https://github.com/theAIGuysCode/yolov4-deepsort\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# comment out below line to enable tensorflow logging outputs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import time\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import core.utils as utils\n",
    "from core.yolov4 import filter_boxes\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from core.config import cfg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "# deep sort imports\n",
    "from deep_sort import preprocessing, nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from tools import generate_detections as gdet\n",
    "from vidstab import VidStab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Parameters\n",
    "# Set Framework for Tracking-Points Storage\n",
    "from _collections import deque\n",
    "pts = [deque(maxlen=3000) for _ in range(50000)]\n",
    "\n",
    "# Set Parameters for Subsampling Import Frame\n",
    "counter = []\n",
    "n_width = int(6) # Number of subsets horizontally\n",
    "n_height = int(4) # Number of subsets vertically\n",
    "subset_x_start = int(1750) # Only needed for single tile processing, Left top corner (x = Value horizontally)\n",
    "subset_y_start = int(500) # Only needed for single tile processing, Left top corner (y = Value vertically)\n",
    "size_of_subset = int(1000) #Dimension of Subsampling Frame, e.g. 416\n",
    "\n",
    "frame_num = 0\n",
    "\n",
    "# Create Empty Bounding-Boxes and Score-Arrays for Object Detection to start with\n",
    "final_bboxes = np.empty((0,4)) # [min_x, miny, max_x, max_y]\n",
    "final_scores = np.empty((0,1))\n",
    "\n",
    "# Set Parameters for Object Detection\n",
    "framework = str('tf') # tf for Tensorflow-Framework\n",
    "weights = str('./checkpoints/yolov4-416') # Path to Weights-file, original pretrained weights\n",
    "#weights = str('./checkpoints/yolov4-416-obj-2400') # Path to Weights-file, own training\n",
    "\n",
    "size = int(416) # Size of Input-Image of Network, e.g. 416 in case of yolo --> Targeted Resize Dimension\n",
    "\n",
    "#Path to Video-Files\n",
    "#video = str('./data/video/20210323-Schräg/Schräg-90m-45Grad-1.mov') # Path to Input-Video, '0' for Webcam, #Dimension 3840 x 2160\n",
    "video = str('./data/video/20210408-Nadir/Nadir-90m-7.mov') # Path to Input-Video, '0' for Webcam, #Dimension 3840 x 2160\n",
    "#video = str('./data/video/20210323-Schräg/Schräg-140m-45Grad-2.mov') # Path to Input-Video, '0' for Webcam, #Dimension 3840 x 2160\n",
    "#video = str('./data/video/20210323-Schräg/Schräg-140m-60Grad-1.mov') # Path to Input-Video, '0' for Webcam, #Dimension 3840 x 2160\n",
    "#video = str('./data/video/20210408-Nadir/Nadir-90m-5.mov') # Path to Input-Video, '0' for Webcam, #Dimension 3840 x 2160\n",
    "#video = str(r'C:\\Users\\patri\\Dropbox\\FHNW\\Geomatik_Privat\\_MSc\\VP1\\03_Rohdaten\\03_01_Aufnahmen\\IGEO\\Befliegungen_Nadir_BS-31-03-21\\D1\\DJI_0001.MP4') # Path to Input-Video, '0' for Webcam, #Dimension 3840 x 2160\n",
    "#video = str('./data/video/20210323-Nadir/Nadir-140m-2.mov') # Path to Input-Video, '0' for Webcam, #Dimension 3840 x 2160\n",
    "\n",
    "\n",
    "\n",
    "video_stabilized = str('./data/video//Output/Stabilized.avi')\n",
    "output_video_subframe = str('./data/video/Output/D1-DJI_0001-Detektion-Subframe.avi') # Path to Output-Video\n",
    "output_video = str('./data/video/Output/D1-DJI_0001--Detektion.avi') # Path to Output-Video\n",
    "\n",
    "\n",
    "bbox_output = str('./data/video/Output/D1-DJI_0001--Detektion-bbox_output.txt') # Path to BBox-Output\n",
    "\n",
    "\n",
    "fps = float(30.0) # Frames per Second for Output Video File\n",
    "size_output = (size_of_subset,size_of_subset)\n",
    "iou = float(0.45) # IOU-Threshold, e.g. 0.45\n",
    "score = float(0.50) # Score-Threshold, e.g. 0.50\n",
    "\n",
    "# Set Parameters for Tracking\n",
    "# Definition of the parameters\n",
    "max_cosine_distance = 0.9 # e.g. 0.4\n",
    "nn_budget = None #e.g. None\n",
    "nms_max_overlap = 1.0 # e.g. 1.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(anchors_path, tiny=False):\n",
    "    anchors = np.array(anchors_path)\n",
    "    return anchors.reshape(3, 3, 2)\n",
    "\n",
    "def read_class_names(class_file_name):\n",
    "    names = {}\n",
    "    with open(class_file_name, 'r') as data:\n",
    "        for ID, name in enumerate(data):\n",
    "            names[ID] = name.strip('\\n')\n",
    "    return names\n",
    "\n",
    "def format_boxes(bboxes, image_height, image_width):\n",
    "    for box in bboxes:\n",
    "        ymin = int(box[0] * image_height)\n",
    "        xmin = int(box[1] * image_width)\n",
    "        ymax = int(box[2] * image_height)\n",
    "        xmax = int(box[3] * image_width)\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "        box[0], box[1], box[2], box[3] = xmin, ymin, width, height\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load configuration for object detector\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "STRIDES = np.array(cfg.YOLO.STRIDES)\n",
    "\n",
    "ANCHORS = get_anchors(cfg.YOLO.ANCHORS, False)\n",
    "XYSCALE = cfg.YOLO.XYSCALE\n",
    "NUM_CLASS = len(read_class_names(cfg.YOLO.CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize deep sort\n",
    "model_filename = 'model_data/mars-small128.pb' # TF-Modell for DeepSort\n",
    "encoder = gdet.create_box_encoder(model_filename, batch_size=2)\n",
    "# calculate cosine distance metric\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "# initialize tracker\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "# Load Object-Detetion Model\n",
    "saved_model_loaded = tf.saved_model.load(weights, tags=[tag_constants.SERVING])\n",
    "infer = saved_model_loaded.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stabilize Video and save to File \"video_stabilized\" (takes a while, not working at the moment)\n",
    "stabilizer = VidStab(kp_method='FAST', threshold=42, nonmaxSuppression=False)\n",
    "stabilizer.stabilize(input_path = video, output_path = video_stabilized, border_type = 'black', border_size=100)\n",
    "\n",
    "stabilizer.plot_trajectory()\n",
    "plt.show()\n",
    "\n",
    "stabilizer.plot_transforms()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin video capture\n",
    "vid = cv2.VideoCapture(video)\n",
    "\n",
    "# get dimension of video input\n",
    "width_input  = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))   # width`\n",
    "height_input = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))  #  `height`\n",
    "\n",
    "\n",
    "# initialize video save optionen\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_video_subframe,fourcc, fps, size_output) # Output for only one subframe\n",
    "out_a = cv2.VideoWriter(output_video,fourcc, fps, (width_input,height_input)) # Output of whole frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Init successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <h1> Code for running through only 1 sub-frame-tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbbox_output_file = open(bbox_output, \"w\") # Open File to store BBox-Coordinates\n",
    "# While-loop = True\n",
    "running = True\n",
    "while running:\n",
    "    # Capture frame-by-frame\n",
    "    return_value, main_frame = vid.read()\n",
    "    main_frame = cv2.cvtColor(main_frame, cv2.COLOR_BGR2RGB)\n",
    "    main_frame_edit = main_frame\n",
    "    sub_frame = main_frame[subset_y_start:subset_y_start + size_of_subset,\n",
    "                           subset_x_start:subset_x_start + size_of_subset]\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    frame_num +=1\n",
    "    print('Frame #: ', frame_num)\n",
    "    image_data = cv2.resize(sub_frame, (size, size))\n",
    "    image_data = image_data / 255.\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "    start_time = time.time()\n",
    "\n",
    "    batch_data = tf.constant(image_data)\n",
    "    pred_bbox = infer(batch_data)\n",
    "    for key, value in pred_bbox.items():\n",
    "        boxes = value[:, :, 0:4]\n",
    "        pred_conf = value[:, :, 4:]\n",
    "    \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "    boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "    scores=tf.reshape(\n",
    "        pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "    max_output_size_per_class=500, #50\n",
    "    max_total_size=500, #50\n",
    "    iou_threshold=iou,\n",
    "    score_threshold=score)\n",
    "                        \n",
    "\n",
    "    # convert data to numpy arrays and slice out unused elements\n",
    "    num_objects = valid_detections.numpy()[0]\n",
    "    bboxes = boxes.numpy()[0]\n",
    "    bboxes = bboxes[0:int(num_objects)]\n",
    "    scores = scores.numpy()[0]\n",
    "    scores = scores[0:int(num_objects)]\n",
    "    classes = classes.numpy()[0]\n",
    "    classes = classes[0:int(num_objects)]\n",
    "    \n",
    "\n",
    "    # format bounding boxes from normalized ymin, xmin, ymax, xmax ---> xmin, ymin, width, height\n",
    "    original_h, original_w, _ = sub_frame.shape\n",
    "    bboxes = utils.format_boxes(bboxes, original_h, original_w)\n",
    "    \n",
    "    # store all predictions in one parameter for simplicity when calling functions\n",
    "    pred_bbox = [bboxes, scores, classes, num_objects]\n",
    "    \n",
    "    # read in all class names from config\n",
    "    class_names = utils.read_class_names(cfg.YOLO.CLASSES)\n",
    "    \n",
    "    # by default allow all classes in .names file\n",
    "    allowed_classes = list(class_names.values())\n",
    "            \n",
    "    # custom allowed classes (uncomment line below to customize tracker for only people)\n",
    "    #allowed_classes = ['person', 'car', 'truck', 'bus', 'motorbike', 'bicycle']\n",
    "\n",
    "    # loop through objects and use class index to get class name, allow only classes in allowed_classes list\n",
    "    names = []\n",
    "    deleted_indx = []\n",
    "    for i in range(num_objects):\n",
    "        class_indx = int(classes[i])\n",
    "        class_name = class_names[class_indx]\n",
    "        if class_name not in allowed_classes:\n",
    "            deleted_indx.append(i)\n",
    "        else:\n",
    "            names.append(class_name)\n",
    "    names = np.array(names)\n",
    "    count = len(names)\n",
    "                \n",
    "    cv2.putText(sub_frame, \"Objects being tracked: {}\".format(count), (5, 35), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 255, 0), 2)\n",
    "    print(\"Objects being tracked: {}\".format(count))\n",
    "    # delete detections that are not in allowed_classes\n",
    "    bboxes = np.delete(bboxes, deleted_indx, axis=0) # [175. 619. 123.  77.] --> xmin, ymin, width, height\n",
    "    scores = np.delete(scores, deleted_indx, axis=0) # [0.98072225 0.7607064]\n",
    "    \n",
    "    #print(\"BBoxes : \" + str(bboxes))\n",
    "    \n",
    "    # encode yolo detections and feed to tracker\n",
    "    features = encoder(sub_frame, bboxes)\n",
    "    detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(bboxes, scores, names, features)]\n",
    "    \n",
    "    #initialize color map\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "    \n",
    "    # run non-maxima supression\n",
    "    boxs = np.array([d.tlwh for d in detections])\n",
    "    scores = np.array([d.confidence for d in detections])\n",
    "    classes = np.array([d.class_name for d in detections])\n",
    "    indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
    "    detections = [detections[i] for i in indices]       \n",
    "    \n",
    "    # Call the tracker\n",
    "    tracker.predict()\n",
    "    tracker.update(detections)\n",
    "    \n",
    "    # update tracks\n",
    "    for track in tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue \n",
    "        bbox = track.to_tlbr()\n",
    "        class_name = track.get_class()\n",
    "     \n",
    "        color = colors[int(track.track_id) % len(colors)]\n",
    "        color = [i * 255 for i in color]\n",
    "                \n",
    "    #Trajectories\n",
    "        center = (int(((bbox[0]) + (bbox[2]))/2), int(((bbox[1])+(bbox[3]))/2))\n",
    "        pts[track.track_id].append(center)\n",
    "        for j in range(1, len(pts[track.track_id])):\n",
    "            if pts[track.track_id][j-1] is None or pts[track.track_id][j] is None:\n",
    "                continue\n",
    "            thickness = 2\n",
    "            #thickness = int(np.sqrt(64/float(j+1))*2)\n",
    "            cv2.line(sub_frame, (pts[track.track_id][j-1]), (pts[track.track_id][j]), color, thickness)\n",
    "    \n",
    "    # draw bbox on screen\n",
    "        bbox_topleft = (subset_x_start + int(bbox[0]), subset_y_start + int(bbox[1]))\n",
    "        bbox_bottomright = (subset_x_start +  int(bbox[2]), subset_y_start  + int(bbox[3]))\n",
    "        bbox_topleft_fill = (subset_x_start + int(bbox[0]), subset_y_start + int(bbox[1]-30))\n",
    "        bbox_bottomrigh_fill = (subset_x_start + int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, subset_y_start + int(bbox[1]))\n",
    "        bbox_text_position = (subset_x_start + int(bbox[0]), subset_y_start + int(bbox[1]-10))\n",
    "        cv2.rectangle(main_frame_edit, bbox_topleft, \n",
    "                      bbox_bottomright, color, 2)\n",
    "        cv2.rectangle(main_frame_edit, bbox_topleft_fill, \n",
    "                      bbox_bottomrigh_fill, color, -1)\n",
    "        cv2.putText(main_frame_edit, class_name + \"-\" + str(track.track_id),bbox_text_position,0, 0.75, (255,255,255),2)\n",
    "    \n",
    "    # Print and Store Details of BBox in Console and File\n",
    "\n",
    "        print(\"Tracker ID: {}, Class: {},  BBox Coords (xmin, ymin, xmax, ymax): {}\".format(str(track.track_id), \n",
    "                                                                                            class_name, \n",
    "                                                                                            (subset_x_start + int(bbox[0]), \n",
    "                                                                                             subset_y_start + int(bbox[1]), \n",
    "                                                                                             subset_x_start + int(bbox[2]), \n",
    "                                                                                             subset_y_start + int(bbox[3]))))\n",
    "        \n",
    "        bbbox_output_file.write(\"Frame-Number: \"+ str(frame_num)+\", Tracker ID: {}, Class: {},  BBox Coords (xmin, ymin, xmax, ymax): {} \\n\".format(str(track.track_id), \n",
    "                                                                                            class_name, \n",
    "                                                                                            (subset_x_start + int(bbox[0]), \n",
    "                                                                                             subset_y_start + int(bbox[1]), \n",
    "                                                                                             subset_x_start + int(bbox[2]), \n",
    "                                                                                             subset_y_start + int(bbox[3]))))\n",
    "    \n",
    "    # calculate frames per second of running detections\n",
    "    fps = 1 / (time.time() - start_time) #1.0\n",
    "    print(\"FPS: %.2f\" % fps)\n",
    "    result = np.asarray(sub_frame)\n",
    "    result = cv2.cvtColor(sub_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "\n",
    "    cv2.imshow(\"Output Video\", result)\n",
    "\n",
    "    #Show single subtile of main frame\n",
    "    main_frame_edit = cv2.rectangle(main_frame_edit, (subset_x_start,subset_y_start),\n",
    "                                    (subset_x_start + size_of_subset,subset_y_start + size_of_subset),\n",
    "                                    (255,0,0), 5) \n",
    "    main_frame_tile = np.asarray(main_frame_edit)\n",
    "    main_frame_tile = cv2.cvtColor(main_frame_tile, cv2.COLOR_RGB2BGR)\n",
    "    cv2.namedWindow(\"Main_Frame\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Main_Frame\", 1920,1080)\n",
    "    cv2.imshow(\"Main_Frame\", main_frame_tile)\n",
    "    \n",
    "    \n",
    "    \n",
    "    out.write(result)\n",
    "    out_a.write(main_frame_tile)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        running = False\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "bbbox_output_file.close() # Close BBox-Text-File\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Loop for running through all sub-frame-tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbbox_output_file = open(bbox_output, \"w\") # Open File to store BBox-Coordinates\n",
    "\n",
    "#Initialize arrays for summed up bboxes per main frame\n",
    "bboxes_all = np.array([[1,1,10,10]])\n",
    "bboxes_all = bboxes_all.astype('float32')\n",
    "scores_all = np.array([0.9999999999], dtype = 'float32')\n",
    "names_all = ['person']\n",
    "\n",
    "\n",
    "\n",
    "# While-loop = True\n",
    "running = True\n",
    "while running:\n",
    "    # Capture frame-by-frame\n",
    "    return_value, main_frame = vid.read()\n",
    "    main_frame = cv2.cvtColor(main_frame, cv2.COLOR_BGR2RGB)\n",
    "    main_frame_edit = main_frame\n",
    "    frame_num +=1\n",
    "    print('Frame #: ', frame_num)\n",
    "    \n",
    "    for u in range(1,n_width):\n",
    "        for v in range (1,n_height):\n",
    "            sub_frame = main_frame[v * size_of_subset:(v+1) * size_of_subset,\n",
    "                                   u * size_of_subset:(u+1) *  size_of_subset]\n",
    "\n",
    "    \n",
    "            image_data = cv2.resize(sub_frame, (size, size))\n",
    "            image_data = image_data / 255.\n",
    "            image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "            start_time = time.time()\n",
    "\n",
    "            batch_data = tf.constant(image_data)\n",
    "            pred_bbox = infer(batch_data)\n",
    "            for key, value in pred_bbox.items():\n",
    "                boxes = value[:, :, 0:4]\n",
    "                pred_conf = value[:, :, 4:]\n",
    "\n",
    "            boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "            boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "            scores=tf.reshape(\n",
    "                pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "            max_output_size_per_class=500, #50\n",
    "            max_total_size=500, #50\n",
    "            iou_threshold=iou,\n",
    "            score_threshold=score)\n",
    "                        \n",
    "\n",
    "            # convert data to numpy arrays and slice out unused elements\n",
    "            num_objects = valid_detections.numpy()[0]\n",
    "            bboxes = boxes.numpy()[0]\n",
    "            bboxes = bboxes[0:int(num_objects)]\n",
    "            scores = scores.numpy()[0]\n",
    "            scores = scores[0:int(num_objects)]\n",
    "            classes = classes.numpy()[0]\n",
    "            classes = classes[0:int(num_objects)]\n",
    "    \n",
    "\n",
    "            # format bounding boxes from normalized ymin, xmin, ymax, xmax ---> xmin, ymin, width, height\n",
    "            original_h, original_w, _ = sub_frame.shape\n",
    "            bboxes = utils.format_boxes(bboxes, original_h, original_w)\n",
    "\n",
    "            # store all predictions in one parameter for simplicity when calling functions\n",
    "            pred_bbox = [bboxes, scores, classes, num_objects]\n",
    "\n",
    "            # read in all class names from config\n",
    "            class_names = utils.read_class_names(cfg.YOLO.CLASSES)\n",
    "\n",
    "            # by default allow all classes in .names file\n",
    "            #allowed_classes = list(class_names.values())\n",
    "\n",
    "            # custom allowed classes (uncomment line below to customize tracker for only people)\n",
    "            allowed_classes = ['person', 'car', 'truck', 'bus', 'motorbike', 'bicycle']\n",
    "\n",
    "            # loop through objects and use class index to get class name, allow only classes in allowed_classes list\n",
    "            names = []\n",
    "            deleted_indx = []\n",
    "            for i in range(num_objects):\n",
    "                class_indx = int(classes[i])\n",
    "                class_name = class_names[class_indx]\n",
    "                if class_name not in allowed_classes:\n",
    "                    deleted_indx.append(i)\n",
    "                else:\n",
    "                    names.append(class_name)\n",
    "            names = np.array(names)\n",
    "            count = len(names)\n",
    "            \n",
    "            cv2.putText(sub_frame, \"Objects being tracked: {}\".format(count), (5, 35), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 255, 0), 2)\n",
    "            print(\"Objects being tracked: {}\".format(count))\n",
    "            # delete detections that are not in allowed_classes\n",
    "            bboxes = np.delete(bboxes, deleted_indx, axis=0) # [175. 619. 123.  77.] --> xmin, ymin, width, height\n",
    "            scores = np.delete(scores, deleted_indx, axis=0) # [0.98072225 0.7607064]\n",
    "            print(\"Bboxes: \" + str(bboxes))\n",
    "            print(\"Scores: \" + str(scores))\n",
    "            \n",
    "            # Transform Translation to get from sub frame to main frame coordinates\n",
    "            \n",
    "            dummy_bboxes = [(u) * size_of_subset, (v) * size_of_subset, 0, 0]         \n",
    "            bboxes_temp = np.add (bboxes,dummy_bboxes) \n",
    "            print(\"dummy_bboxes: \" + str(dummy_bboxes))\n",
    "            print(\"Bboxes_temp: \" + str(bboxes_temp))\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Stack sub-frames detections to main frame detections\n",
    "            bboxes_all = np.vstack((bboxes_all,bboxes_temp))\n",
    "            scores_all = np.hstack((scores_all,scores))\n",
    "            names_all = np.hstack((names_all,names))\n",
    "            \n",
    "            print(\"u: \" + str(u))\n",
    "            print(\"v: \" + str(v))\n",
    "            print(\"Bboxes_all: \" + str(bboxes_all))\n",
    "            print(\"Scores_all: \" + str(scores_all))\n",
    "            print(\"Names_all: \" + str(names_all))\n",
    "    \n",
    "    # encode yolo detections and feed to tracker\n",
    "    features = encoder(main_frame, bboxes_all)\n",
    "    detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature \n",
    "                  in zip(bboxes_all, scores_all, names_all, features)]\n",
    "    \n",
    "    #initialize color map\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "    \n",
    "    # run non-maxima supression\n",
    "    boxs = np.array([d.tlwh for d in detections])\n",
    "    scores = np.array([d.confidence for d in detections])\n",
    "    classes = np.array([d.class_name for d in detections])\n",
    "    indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
    "    detections = [detections[i] for i in indices]       \n",
    "    \n",
    "    # Call the tracker\n",
    "    tracker.predict()\n",
    "    tracker.update(detections)\n",
    "    \n",
    "    # update tracks\n",
    "    for track in tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue \n",
    "        bbox = track.to_tlbr()\n",
    "        class_name = track.get_class()\n",
    "        print(\"bbox: \" + str(bbox))\n",
    "     \n",
    "        color = colors[int(track.track_id) % len(colors)]\n",
    "        color = [i * 255 for i in color]\n",
    "                \n",
    "    #Trajectories\n",
    "        center = (int(((bbox[0]) + (bbox[2]))/2), int(((bbox[1])+(bbox[3]))/2))\n",
    "        pts[track.track_id].append(center)\n",
    "        for j in range(1, len(pts[track.track_id])):\n",
    "            if pts[track.track_id][j-1] is None or pts[track.track_id][j] is None:\n",
    "                continue\n",
    "            thickness = 2\n",
    "            #thickness = int(np.sqrt(64/float(j+1))*2)\n",
    "            cv2.line(main_frame, (pts[track.track_id][j-1]), (pts[track.track_id][j]), color, thickness)\n",
    "    \n",
    "    # draw bbox on screen\n",
    "        bbox_topleft = (int(bbox[0]),int(bbox[1]))\n",
    "        bbox_bottomright = (int(bbox[2]), int(bbox[3]))\n",
    "        bbox_topleft_fill = (int(bbox[0]),int(bbox[1]-30))\n",
    "        bbox_bottomrigh_fill = (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17,int(bbox[1]))\n",
    "        bbox_text_position = (int(bbox[0]),int(bbox[1]-10))\n",
    "        cv2.rectangle(main_frame_edit, bbox_topleft, \n",
    "                      bbox_bottomright, color, 2)\n",
    "        cv2.rectangle(main_frame_edit, bbox_topleft_fill, \n",
    "                      bbox_bottomrigh_fill, color, -1)\n",
    "        cv2.putText(main_frame_edit, class_name + \"-\" + str(track.track_id),bbox_text_position,0, 0.75, (255,255,255),2)\n",
    "    \n",
    "    # Print and Store Details of BBox in Console and File\n",
    "\n",
    "        print(\"Tracker ID: {}, Class: {},  BBox Coords (xmin, ymin, xmax, ymax): {}\".format(str(track.track_id), \n",
    "                                                                                            class_name, \n",
    "                                                                                            (int(bbox[0]), \n",
    "                                                                                             int(bbox[1]), \n",
    "                                                                                             int(bbox[2]), \n",
    "                                                                                             int(bbox[3]))))\n",
    "        \n",
    "        bbbox_output_file.write(\"Frame-Number: \"+ str(frame_num)+\", Tracker ID: {}, Class: {},  BBox Coords (xmin, ymin, xmax, ymax): {} \\n\".format(str(track.track_id), \n",
    "                                                                                            class_name, \n",
    "                                                                                            (int(bbox[0]), \n",
    "                                                                                             int(bbox[1]), \n",
    "                                                                                             int(bbox[2]), \n",
    "                                                                                             int(bbox[3]))))\n",
    "    \n",
    "    # calculate frames per second of running detections\n",
    "    fps = 1 / (time.time() - start_time) #1.0\n",
    "    print(\"FPS: %.2f\" % fps)\n",
    "    result = np.asarray(sub_frame)\n",
    "    result = cv2.cvtColor(sub_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "\n",
    "    cv2.imshow(\"Output Video\", result)\n",
    "\n",
    "    #Show single subtile of main frame\n",
    "    main_frame_edit = cv2.rectangle(main_frame_edit, (subset_x_start,subset_y_start),\n",
    "                                    (subset_x_start + size_of_subset,subset_y_start + size_of_subset),\n",
    "                                    (255,0,0), 5) \n",
    "    main_frame_tile = np.asarray(main_frame_edit)\n",
    "    main_frame_tile = cv2.cvtColor(main_frame_tile, cv2.COLOR_RGB2BGR)\n",
    "    cv2.namedWindow(\"Main_Frame\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Main_Frame\", 1920,1080)\n",
    "    cv2.imshow(\"Main_Frame\", main_frame_tile)\n",
    "    \n",
    "    \n",
    "    \n",
    "    out.write(result)\n",
    "    out_a.write(main_frame_tile)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        running = False\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "bbbox_output_file.close() # Close BBox-Text-File\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "            \"\"\"\n",
    "            B = np.array([[u*size_of_subset],[v*size_of_subset],[u*size_of_subset],[v*size_of_subset]])\n",
    "            B = np.transpose(B, axes = None)\n",
    "            \n",
    "            #print(bboxes.shape)\n",
    "            #print(B.shape)\n",
    "            \n",
    "            bboxes = bboxes + B[:None]\n",
    "            \n",
    "            #Create final \n",
    "            final_bboxes = np.append(final_bboxes,bboxes)\n",
    "            final_scores = np.append(final_scores,scores)\n",
    "            bbox = final_bboxes\n",
    "            \"\"\"\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"                   \n",
    "           # encode yolo detections and feed to tracker\n",
    "            features = encoder(frame, bboxes)\n",
    "            detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(bboxes, scores, names, features)]\n",
    "    \n",
    "            #initialize color map\n",
    "            cmap = plt.get_cmap('tab20b')\n",
    "            colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "    \n",
    "            # run non-maxima supression\n",
    "            boxs = np.array([d.tlwh for d in detections])\n",
    "            scores = np.array([d.confidence for d in detections])\n",
    "            classes = np.array([d.class_name for d in detections])\n",
    "            indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
    "            detections = [detections[i] for i in indices]       \n",
    "            print(boxs)\n",
    "            \n",
    "            # Call the tracker\n",
    "            tracker.predict()\n",
    "            tracker.update(detections)\n",
    "    \n",
    "            # update tracks\n",
    "            for track in tracker.tracks:\n",
    "                if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                    continue \n",
    "                bbox = track.to_tlbr()\n",
    "                class_name = track.get_class()\n",
    "     \n",
    "                color = colors[int(track.track_id) % len(colors)]\n",
    "                color = [i * 255 for i in color]\n",
    "                \n",
    "            #Trajectories\n",
    "                center = (int(((bbox[0]) + (bbox[2]))/2), int(((bbox[1])+(bbox[3]))/2))\n",
    "                pts[track.track_id].append(center)\n",
    "                for j in range(1, len(pts[track.track_id])):\n",
    "                    if pts[track.track_id][j-1] is None or pts[track.track_id][j] is None:\n",
    "                        continue\n",
    "                    thickness = 2\n",
    "                    #thickness = int(np.sqrt(64/float(j+1))*2)\n",
    "                    cv2.line(sub_frame, (pts[track.track_id][j-1]), (pts[track.track_id][j]), color, thickness)\n",
    "    \n",
    "            # draw bbox on screen\n",
    "                print(bbox)\n",
    "                cv2.rectangle(sub_frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbbox[3])), color, 2)\n",
    "                cv2.rectangle(sub_frame, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, int(bbox[1])), color, -1)\n",
    "                cv2.putText(sub_frame, class_name + \"-\" + str(track.track_id),(int(bbox[0]), int(bbox[1]-10)),0, 0.75, (255,255,255),2)\n",
    "    \n",
    "            # if enable info flag then print details about each track\n",
    "                print(\"Tracker ID: {}, Class: {},  BBox Coords (xmin, ymin, xmax, ymax): {}\".format(str(track.track_id), class_name, (int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3]))))\n",
    "    \n",
    "            # calculate frames per second of running detections\n",
    "            fps = 1 / (time.time() - start_time) #1.0\n",
    "            print(\"FPS: %.2f\" % fps)\n",
    "            result = np.asarray(sub_frame)\n",
    "            #result = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When everything done, release the capture\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbbox_output_file = open(bbox_output, \"w\") # Open File to store BBox-Coordinates\n",
    "# While-loop = True\n",
    "running = True\n",
    "while running:\n",
    "    # Capture frame-by-frame\n",
    "    return_value, main_frame = vid.read()\n",
    "    main_frame = cv2.cvtColor(main_frame, cv2.COLOR_BGR2RGB)\n",
    "    main_frame_edit = main_frame\n",
    "    sub_frame = main_frame[subset_y_start:subset_y_start + size_of_subset,\n",
    "                           subset_x_start:subset_x_start + size_of_subset]\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    frame_num +=1\n",
    "    print('Frame #: ', frame_num)\n",
    "    image_data = cv2.resize(sub_frame, (size, size))\n",
    "    image_data = image_data / 255.\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "    start_time = time.time()\n",
    "\n",
    "    batch_data = tf.constant(image_data)\n",
    "    pred_bbox = infer(batch_data)\n",
    "    for key, value in pred_bbox.items():\n",
    "        boxes = value[:, :, 0:4]\n",
    "        pred_conf = value[:, :, 4:]\n",
    "    \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "    boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "    scores=tf.reshape(\n",
    "        pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "    max_output_size_per_class=500, #50\n",
    "    max_total_size=500, #50\n",
    "    iou_threshold=iou,\n",
    "    score_threshold=score)\n",
    "                        \n",
    "\n",
    "    # convert data to numpy arrays and slice out unused elements\n",
    "    num_objects = valid_detections.numpy()[0]\n",
    "    bboxes = boxes.numpy()[0]\n",
    "    bboxes = bboxes[0:int(num_objects)]\n",
    "    scores = scores.numpy()[0]\n",
    "    scores = scores[0:int(num_objects)]\n",
    "    classes = classes.numpy()[0]\n",
    "    classes = classes[0:int(num_objects)]\n",
    "    \n",
    "\n",
    "    # format bounding boxes from normalized ymin, xmin, ymax, xmax ---> xmin, ymin, width, height\n",
    "    original_h, original_w, _ = sub_frame.shape\n",
    "    bboxes = utils.format_boxes(bboxes, original_h, original_w)\n",
    "    \n",
    "    # store all predictions in one parameter for simplicity when calling functions\n",
    "    pred_bbox = [bboxes, scores, classes, num_objects]\n",
    "    \n",
    "    # read in all class names from config\n",
    "    class_names = utils.read_class_names(cfg.YOLO.CLASSES)\n",
    "    \n",
    "    # by default allow all classes in .names file\n",
    "    allowed_classes = list(class_names.values())\n",
    "            \n",
    "    # custom allowed classes (uncomment line below to customize tracker for only people)\n",
    "    #allowed_classes = ['person', 'car', 'truck', 'bus', 'motorbike', 'bicycle']\n",
    "\n",
    "    # loop through objects and use class index to get class name, allow only classes in allowed_classes list\n",
    "    names = []\n",
    "    deleted_indx = []\n",
    "    for i in range(num_objects):\n",
    "        class_indx = int(classes[i])\n",
    "        class_name = class_names[class_indx]\n",
    "        if class_name not in allowed_classes:\n",
    "            deleted_indx.append(i)\n",
    "        else:\n",
    "            names.append(class_name)\n",
    "    names = np.array(names)\n",
    "    count = len(names)\n",
    "            \n",
    "    cv2.putText(sub_frame, \"Objects being tracked: {}\".format(count), (5, 35), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 255, 0), 2)\n",
    "    print(\"Objects being tracked: {}\".format(count))\n",
    "    # delete detections that are not in allowed_classes\n",
    "    bboxes = np.delete(bboxes, deleted_indx, axis=0)\n",
    "    scores = np.delete(scores, deleted_indx, axis=0)\n",
    "    \n",
    "    # encode yolo detections and feed to tracker\n",
    "    features = encoder(sub_frame, bboxes)\n",
    "    detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(bboxes, scores, names, features)]\n",
    "    \n",
    "    #initialize color map\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "    \n",
    "    # run non-maxima supression\n",
    "    boxs = np.array([d.tlwh for d in detections])\n",
    "    scores = np.array([d.confidence for d in detections])\n",
    "    classes = np.array([d.class_name for d in detections])\n",
    "    indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
    "    detections = [detections[i] for i in indices]       \n",
    "    \n",
    "    # Call the tracker\n",
    "    tracker.predict()\n",
    "    tracker.update(detections)\n",
    "    \n",
    "    # update tracks\n",
    "    for track in tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue \n",
    "        bbox = track.to_tlbr()\n",
    "        class_name = track.get_class()\n",
    "     \n",
    "        color = colors[int(track.track_id) % len(colors)]\n",
    "        color = [i * 255 for i in color]\n",
    "                \n",
    "    #Trajectories\n",
    "        center = (int(((bbox[0]) + (bbox[2]))/2), int(((bbox[1])+(bbox[3]))/2))\n",
    "        pts[track.track_id].append(center)\n",
    "        for j in range(1, len(pts[track.track_id])):\n",
    "            if pts[track.track_id][j-1] is None or pts[track.track_id][j] is None:\n",
    "                continue\n",
    "            thickness = 2\n",
    "            #thickness = int(np.sqrt(64/float(j+1))*2)\n",
    "            cv2.line(sub_frame, (pts[track.track_id][j-1]), (pts[track.track_id][j]), color, thickness)\n",
    "    \n",
    "    # draw bbox on screen\n",
    "        bbox_topleft = (subset_x_start + int(bbox[0]), subset_y_start + int(bbox[1]))\n",
    "        bbox_bottomright = (subset_x_start +  int(bbox[2]), subset_y_start  + int(bbox[3]))\n",
    "        bbox_topleft_fill = (subset_x_start + int(bbox[0]), subset_y_start + int(bbox[1]-30))\n",
    "        bbox_bottomrigh_fill = (subset_x_start + int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, subset_y_start + int(bbox[1]))\n",
    "        bbox_text_position = (subset_x_start + int(bbox[0]), subset_y_start + int(bbox[1]-10))\n",
    "        cv2.rectangle(main_frame_edit, bbox_topleft, \n",
    "                      bbox_bottomright, color, 2)\n",
    "        cv2.rectangle(main_frame_edit, bbox_topleft_fill, \n",
    "                      bbox_bottomrigh_fill, color, -1)\n",
    "        cv2.putText(main_frame_edit, class_name + \"-\" + str(track.track_id),bbox_text_position,0, 0.75, (255,255,255),2)\n",
    "    \n",
    "    # Print and Store Details of BBox in Console and File\n",
    "\n",
    "        print(\"Tracker ID: {}, Class: {},  BBox Coords (xmin, ymin, xmax, ymax): {}\".format(str(track.track_id), \n",
    "                                                                                            class_name, \n",
    "                                                                                            (subset_x_start + int(bbox[0]), \n",
    "                                                                                             subset_y_start + int(bbox[1]), \n",
    "                                                                                             subset_x_start + int(bbox[2]), \n",
    "                                                                                             subset_y_start + int(bbox[3]))))\n",
    "        \n",
    "        bbbox_output_file.write(\"Frame-Number: \"+ str(frame_num)+\", Tracker ID: {}, Class: {},  BBox Coords (xmin, ymin, xmax, ymax): {} \\n\".format(str(track.track_id), \n",
    "                                                                                            class_name, \n",
    "                                                                                            (subset_x_start + int(bbox[0]), \n",
    "                                                                                             subset_y_start + int(bbox[1]), \n",
    "                                                                                             subset_x_start + int(bbox[2]), \n",
    "                                                                                             subset_y_start + int(bbox[3]))))\n",
    "    \n",
    "    # calculate frames per second of running detections\n",
    "    fps = 1 / (time.time() - start_time) #1.0\n",
    "    print(\"FPS: %.2f\" % fps)\n",
    "    result = np.asarray(sub_frame)\n",
    "    result = cv2.cvtColor(sub_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "\n",
    "    cv2.imshow(\"Output Video\", result)\n",
    "\n",
    "    #Show single subtile of main frame\n",
    "    main_frame_edit = cv2.rectangle(main_frame_edit, (subset_x_start,subset_y_start),\n",
    "                                    (subset_x_start + size_of_subset,subset_y_start + size_of_subset),\n",
    "                                    (255,0,0), 5) \n",
    "    main_frame_tile = np.asarray(main_frame_edit)\n",
    "    main_frame_tile = cv2.cvtColor(main_frame_tile, cv2.COLOR_RGB2BGR)\n",
    "    cv2.namedWindow(\"Main_Frame\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Main_Frame\", 1920,1080)\n",
    "    cv2.imshow(\"Main_Frame\", main_frame_tile)\n",
    "    \n",
    "    \n",
    "    \n",
    "    out.write(result)\n",
    "    out_a.write(main_frame_tile)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        running = False\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "bbbox_output_file.close() # Close BBox-Text-File\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
