{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f21cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# import DeepLab\n",
    "from model import DeepLabModel, DeepLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd99b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input video file path\n",
    "video = str('./input/video/DJI_0008_short.mp4')\n",
    "\n",
    "# input foto file path\n",
    "foto = 'input/foto/cars.JPG'\n",
    "\n",
    "# output video file path\n",
    "output_video = str('./output/video/test_output.avi') # Path to Output-Video\n",
    "\n",
    "# Frames per Second for Output Video File\n",
    "fps = float(30.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f1ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frameCount: 95\n",
      "frameWidth: 3840\n",
      "frameHeight: 2160\n",
      "videoFPS: 29\n",
      "DURATION: 3.2758620689655173\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_AVI_RATIO,0)\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "videoFPS = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "print (f\"frameCount: {frameCount}\")\n",
    "print (f\"frameWidth: {frameWidth}\")\n",
    "print (f\"frameHeight: {frameHeight}\")\n",
    "print (f\"videoFPS: {videoFPS}\")\n",
    "\n",
    "buf = np.empty((\n",
    "    frameCount,\n",
    "    frameHeight,\n",
    "    frameWidth,\n",
    "    3), np.dtype('uint8'))\n",
    "\n",
    "fc = 0\n",
    "ret = True\n",
    "\n",
    "while (fc < frameCount):\n",
    "    ret, buf[fc] = cap.read()\n",
    "    fc += 1\n",
    "\n",
    "cap.release()\n",
    "videoArray = buf\n",
    "\n",
    "print (f\"DURATION: {frameCount/videoFPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c7ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87bc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dimension of video input\n",
    "width_input  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # width`\n",
    "height_input = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  #  `height`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907f09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize video save optionen\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out_a = cv2.VideoWriter(output_video,fourcc, fps, (width_input,height_input)) # Output of whole frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff458f",
   "metadata": {},
   "source": [
    "# extract an safe video frames\n",
    "vidcap = cv2.VideoCapture(video)\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "  cv2.imwrite(\"frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "  success,image = vidcap.read()\n",
    "  print('Read a new frame: ', success)\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "349b627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init successful!\n"
     ]
    }
   ],
   "source": [
    "print(\"Init successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766ec828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deeplab definitions\n",
    "\n",
    "def create__label_colormap():\n",
    "     return np.asarray([\n",
    "         [0, 0, 0],\n",
    "         [0, 192, 0],\n",
    "         [255, 192, 192],\n",
    "     ])\n",
    "    \n",
    "\n",
    "def label_to_color_image(label):\n",
    "    \"\"\"Adds color defined by the dataset colormap to the label.\n",
    "\n",
    "    Args:\n",
    "    label: A 2D array with integer type, storing the segmentation label.\n",
    "\n",
    "    Returns:\n",
    "    result: A 2D array with floating type. The element of the array\n",
    "      is the color indexed by the corresponding element in the input label\n",
    "      to the PASCAL color map.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If label is not of rank 2 or its value is larger than color\n",
    "      map maximum entry.\n",
    "    \"\"\"\n",
    "    if label.ndim != 2:\n",
    "        raise ValueError('Expect 2-D input label')\n",
    "\n",
    "    colormap = create__label_colormap()\n",
    "\n",
    "    if np.max(label) >= len(colormap):\n",
    "        raise ValueError('label value too large.')\n",
    "\n",
    "    return colormap[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f77a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set basic variables\n",
    "current_frame = 0\n",
    "id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "801ea231",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.11) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-txi80knz\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3816/3508900069.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprev_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.11) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-txi80knz\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "ret, first_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c34f8414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "# -------1--------\n",
    "model = DeepLabModel('model/frozen_inference_graph_cars.pb')\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "cap.set(cv2.CAP_PROP_POS_AVI_RATIO,0)\n",
    "\n",
    "img_array = []\n",
    "\n",
    "while True:\n",
    "    current_frame += 1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        print('finished!')\n",
    "        break\n",
    "        \n",
    "    mask = model.run(Image.fromarray(frame))       \n",
    "    img_array.append(label_to_color_image(mask).astype(np.uint8))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5d994f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----2------\n",
    "size = img_array[0].shape[:2][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d088620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------3------\n",
    "out = cv2.VideoWriter(output_video,cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df83d718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 1025, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_color_image(mask).astype(np.uint8).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c32b208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 576)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93e8b398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b8e8e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c997ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[122, 107, 158],\n",
       "        [119, 104, 155],\n",
       "        [129, 114, 167],\n",
       "        ...,\n",
       "        [ 93, 118, 119],\n",
       "        [ 86, 111, 112],\n",
       "        [ 67,  92,  93]],\n",
       "\n",
       "       [[158, 143, 194],\n",
       "        [156, 141, 192],\n",
       "        [162, 147, 200],\n",
       "        ...,\n",
       "        [ 88, 113, 114],\n",
       "        [ 75, 100, 101],\n",
       "        [ 63,  88,  89]],\n",
       "\n",
       "       [[161, 145, 200],\n",
       "        [160, 144, 199],\n",
       "        [154, 138, 193],\n",
       "        ...,\n",
       "        [ 89, 114, 115],\n",
       "        [ 77, 102, 103],\n",
       "        [ 64,  89,  90]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 24,  23,  17],\n",
       "        [ 31,  30,  24],\n",
       "        [ 34,  33,  27],\n",
       "        ...,\n",
       "        [121, 148, 149],\n",
       "        [115, 142, 143],\n",
       "        [122, 149, 150]],\n",
       "\n",
       "       [[ 22,  21,  15],\n",
       "        [ 27,  26,  20],\n",
       "        [ 31,  30,  24],\n",
       "        ...,\n",
       "        [126, 153, 154],\n",
       "        [121, 148, 149],\n",
       "        [124, 151, 152]],\n",
       "\n",
       "       [[ 26,  25,  19],\n",
       "        [ 22,  21,  15],\n",
       "        [ 20,  19,  13],\n",
       "        ...,\n",
       "        [121, 148, 149],\n",
       "        [125, 152, 153],\n",
       "        [125, 152, 153]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad0fd7ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3816/3960712129.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moriginal_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "original_im = Image.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95cada0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLabModel('model/frozen_inference_graph_cars.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8725a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(label_to_color_image(mask).astype(np.uint8)).save('output/test1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3dc7a6",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f6356e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = model.run(Image.fromarray(buf[94,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60dbbc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1025x576>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(label_to_color_image(mask).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e13290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d5944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
