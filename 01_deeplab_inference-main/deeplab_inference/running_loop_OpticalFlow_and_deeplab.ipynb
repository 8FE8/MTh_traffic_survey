{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "from vidstab import VidStab\n",
    "from PIL import Image\n",
    "from skimage.measure import label, regionprops\n",
    "import os\n",
    "\n",
    "from CentroidTracker import CentroidTracker, progressBar, showWindows, georeference\n",
    "import params\n",
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- import DeepLab\n",
    "from model import DeepLabModel, DeepLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepLab Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- input video file path\n",
    "video = str('./input/DJI_0008_original.MP4')\n",
    "\n",
    "# ---- output video file path\n",
    "output_video = str('./output/DJI_0008_short_DL.avi') # Path to Output-Video\n",
    "\n",
    "# ---- output stabilized video path\n",
    "video_stabilized = str('./repo/output_stab.avi') # Path to stabilized Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stabilize Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stabilize Video and save to File \"video_stabilized\"\n",
    "stabilizer = VidStab(kp_method='FAST', threshold=42, nonmaxSuppression=False)\n",
    "stabilizer.stabilize(input_path = video, output_path = video_stabilized, border_type = 'black', border_size=100)\n",
    "\n",
    "stabilizer.plot_trajectory()\n",
    "plt.show()\n",
    "\n",
    "stabilizer.plot_transforms()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLab Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- deeplab definitions\n",
    "\n",
    "def create__label_colormap():\n",
    "     return np.asarray([\n",
    "         [0, 0, 0],\n",
    "         [0, 192, 0],\n",
    "         [255, 192, 192],\n",
    "     ])\n",
    "    \n",
    "\n",
    "def label_to_color_image(label):\n",
    "    \"\"\"Adds color defined by the dataset colormap to the label.\n",
    "\n",
    "    Args:\n",
    "    label: A 2D array with integer type, storing the segmentation label.\n",
    "\n",
    "    Returns:\n",
    "    result: A 2D array with floating type. The element of the array\n",
    "      is the color indexed by the corresponding element in the input label\n",
    "      to the PASCAL color map.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If label is not of rank 2 or its value is larger than color\n",
    "      map maximum entry.\n",
    "    \"\"\"\n",
    "    if label.ndim != 2:\n",
    "        raise ValueError('Expect 2-D input label')\n",
    "\n",
    "    colormap = create__label_colormap()\n",
    "\n",
    "    if np.max(label) >= len(colormap):\n",
    "        raise ValueError('label value too large.')\n",
    "\n",
    "    return colormap[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_frame = 0\n",
    "\n",
    "# input DeepLab\n",
    "input_DL = './repo/output_short_stab.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- iterate DeepLab trough images\n",
    "\n",
    "model = DeepLabModel('model/frozen_inference_graph_cars.pb')\n",
    "\n",
    "cap = cv2.VideoCapture(input_DL)\n",
    "cap.set(cv2.CAP_PROP_POS_AVI_RATIO,0)\n",
    "\n",
    "img_array = []\n",
    "\n",
    "while True:\n",
    "    current_frame += 1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        print('finished!')\n",
    "        break\n",
    "        \n",
    "    mask = model.run(Image.fromarray(frame))\n",
    "    \n",
    "    label_img = label(mask)\n",
    "    img_array.append(label_to_color_image(mask).astype(np.uint8))\n",
    "    \n",
    "    \n",
    "# ---- translate array\n",
    "size = img_array[0].shape[:2][::-1]\n",
    "\n",
    "# ---- save to video\n",
    "out = cv2.VideoWriter(output_video,cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical Flow Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set basic variables\n",
    "ct = CentroidTracker()\n",
    "current_frame = 0\n",
    "id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backSub = cv2.createBackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Georeferencing\n",
    "coord_pixel0_x = 0\n",
    "coord_pixel0_y = 0\n",
    "scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(output_video)\n",
    "\n",
    "# running the loop\n",
    "# extracting the frames\n",
    "ret, first_frame = capture.read()\n",
    "\n",
    "# converting to gray-scale\n",
    "gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    current_frame += 1\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "#     if frame is None:\n",
    "#         print('finished!')\n",
    "#         break\n",
    "    \n",
    "    \n",
    "    fgMask = backSub.apply(frame)\n",
    "    # optimization of elements\n",
    "    thresh = cv2.threshold(fgMask, params.threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "    se0 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, se0)\n",
    "    kernel_dil = np.ones(params.kernel_dilatation, np.uint8)\n",
    "    thresh = cv2.dilate(thresh, kernel_dil, iterations=1)\n",
    "\n",
    "    se1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "    se2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (41, 41))\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, se1)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, se2)\n",
    "    \n",
    "    # detect the contours on the binary image using cv2.CHAIN_APPROX_NONE\n",
    "    contours, hierarchy = cv2.findContours(image=closed, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "    mask = np.zeros_like(first_frame)\n",
    "    # draw contours on the original image\n",
    "    contours = [x for x in contours if len(x) >= 30]\n",
    "    cv2.drawContours(image=mask, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=2,\n",
    "                     lineType=cv2.LINE_AA)\n",
    "    \n",
    "    rects = []\n",
    "    ROI_number = 0\n",
    "    for cntr in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cntr)\n",
    "        if params.min_width < w < params.max_width and params.min_height < h < params.max_height:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            ROI = mask[y:y + h, x:x + w]\n",
    "            cv2.putText(mask, str(ROI_number), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255))\n",
    "            rects.append([x, y, x + w, y + h])\n",
    "            ROI_number += 1\n",
    "    \n",
    "    \n",
    "    # update centroid tracker using the computed set of bounding box rectangles\n",
    "    objects, life = ct.update(rects)\n",
    "    \n",
    "    #build path in swiss coordinate system\n",
    "    if objects is not None:\n",
    "        for (objectID, centroid) in objects.items():\n",
    "            if life[objectID] > params.min_life:\n",
    "                # draw both the ID of the object and the centroid of the object on the output frame\n",
    "                text = \"ID {}\".format(objectID)\n",
    "                x = centroid[0]\n",
    "                y = centroid[1]\n",
    "                cv2.putText(frame, text, (x - 20, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                cv2.circle(frame, (x, y), 4, (255, 255, 255), -1)\n",
    "                if objectID in path.keys():\n",
    "                    path[objectID].append((coord_pixel0_x+(x*scale), coord_pixel0_y-(y*scale)))\n",
    "                else:\n",
    "                    path[objectID] = [(coord_pixel0_x+(x*scale), coord_pixel0_y-(y*scale))]\n",
    "                    \n",
    "    # End time\n",
    "    end = time.time()\n",
    "    # Calculate frames per second\n",
    "    fps = round(current_frame / (end-start), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    imS = cv2.resize(mask, (960, 540))                    # Resize image\n",
    "    cv2.imshow(\"output\", imS) \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############----------- RUN ALL ABOVE ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
