{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "from CentroidTracker import CentroidTracker, progressBar, showWindows, georeference\n",
    "import params\n",
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "import os\n",
    "from vidstab import VidStab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- input video file path\n",
    "video = './input/DJI_0008_short.mp4'\n",
    "video_stabilized = './repo/output_short_stab.avi' # Path to stabilized Video\n",
    "\n",
    "\n",
    "path = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stabilize Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stabilize Video and save to File \"video_stabilized\"\n",
    "stabilizer = VidStab(kp_method='FAST', threshold=42, nonmaxSuppression=False)\n",
    "stabilizer.stabilize(input_path = video, output_path = video_stabilized, border_type = 'black', border_size=100)\n",
    "\n",
    "stabilizer.plot_trajectory()\n",
    "plt.show()\n",
    "\n",
    "stabilizer.plot_transforms()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set basic variables\n",
    "ct = CentroidTracker()\n",
    "current_frame = 0\n",
    "id = 1\n",
    "path = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backSub = cv2.createBackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(video_stabilized)\n",
    "\n",
    "# running the loop\n",
    "# extracting the frames\n",
    "ret, first_frame = capture.read()\n",
    "\n",
    "# converting to gray-scale\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = cv2.goodFeaturesToTrack(prev_gray, mask=None, **params.feature_params)\n",
    "mask = np.zeros_like(first_frame)\n",
    "mask2 = np.zeros_like(first_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Georeferencing\n",
    "coord_pixel0_x = 0\n",
    "coord_pixel0_y = 0\n",
    "scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    current_frame += 1\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "#     if frame is None:\n",
    "#         print('finished!')\n",
    "#         break\n",
    "    \n",
    "    \n",
    "    fgMask = backSub.apply(frame)\n",
    "    # optimization of elements\n",
    "    thresh = cv2.threshold(fgMask, params.threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "    se0 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, se0)\n",
    "    kernel_dil = np.ones(params.kernel_dilatation, np.uint8)\n",
    "    thresh = cv2.dilate(thresh, kernel_dil, iterations=1)\n",
    "\n",
    "    se1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "    se2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (41, 41))\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, se1)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, se2)\n",
    "    \n",
    "    # detect the contours on the binary image using cv2.CHAIN_APPROX_NONE\n",
    "    contours, hierarchy = cv2.findContours(image=closed, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "    mask = np.zeros_like(first_frame)\n",
    "    # draw contours on the original image\n",
    "    contours = [x for x in contours if len(x) >= 30]\n",
    "    cv2.drawContours(image=mask, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=2,\n",
    "                     lineType=cv2.LINE_AA)\n",
    "    \n",
    "    rects = []\n",
    "    ROI_number = 0\n",
    "    for cntr in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cntr)\n",
    "        if params.min_width < w < params.max_width and params.min_height < h < params.max_height:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            ROI = mask[y:y + h, x:x + w]\n",
    "            cv2.putText(mask, str(ROI_number), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255))\n",
    "            rects.append([x, y, x + w, y + h])\n",
    "            ROI_number += 1\n",
    "    \n",
    "    \n",
    "    # update centroid tracker using the computed set of bounding box rectangles\n",
    "    objects, life = ct.update(rects)\n",
    "    \n",
    "    #build path in swiss coordinate system\n",
    "    if objects is not None:\n",
    "        for (objectID, centroid) in objects.items():\n",
    "            if life[objectID] > params.min_life:\n",
    "                # draw both the ID of the object and the centroid of the object on the output frame\n",
    "                text = \"ID {}\".format(objectID)\n",
    "                x = centroid[0]\n",
    "                y = centroid[1]\n",
    "                cv2.putText(frame, text, (x - 20, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 100, (255, 255, 255), 50)\n",
    "                cv2.circle(frame, (x, y), 4, (255, 255, 255), -1)\n",
    "                if objectID in path.keys():\n",
    "                    path[objectID].append((coord_pixel0_x+(x*scale), coord_pixel0_y-(y*scale)))\n",
    "                else:\n",
    "                    path[objectID] = [(coord_pixel0_x+(x*scale), coord_pixel0_y-(y*scale))]\n",
    "                    \n",
    "    # End time\n",
    "    end = time.time()\n",
    "    # Calculate frames per second\n",
    "    fps = round(current_frame / (end-start), 2)\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"output\", mask)\n",
    "#     imS = cv2.resize(mask, (1100, 800))                    # Resize image\n",
    "#     cv2.imshow(\"output\", imS)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############----------- RUN ALL ABOVE ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
